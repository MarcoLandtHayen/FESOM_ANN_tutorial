{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e6578131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries:\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3eaa07d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set relative path to data:\n",
    "path_to_data = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee861294",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "We have simulated temperatur fluxes from a coarse grained simulation with $40km$ resolution. Data is provided on a FESOM grid. Furthermore, we have simulated temperatur fluxes from a fine grained simulation with $10km$ resolution as ground truth data. This ground truth data can be aggregated to a $40km$ resolution as a third data set, which still contains effects from the fine grained simulation and thus, carries more information compared to the raw coarse grained simulation.\n",
    "\n",
    "As target, we aim to infer these aggregated temperature fluxes on a $40km$ resolution.\n",
    "\n",
    "In a first step, we plan to use Rossby radius $R_D$, buoyancy frequency $N^2$ and isopycnal slopes $S_x$ and $S_y$ as input parameters. Additionally, we intend to use simulated temperatur fluxes $u'T'$ and $v'T'$ from the raw coarse grained simulation with $40km$ resolution as input.\n",
    "\n",
    "**Note:** So far, we don't have all data, yet. Until we have the final data, we need to work with dummy data in this tutorial. This means, we only have certain parameters and work with an extract in time and only consider a limited number of vertical levels, for illustration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b442784c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope_x shape (variables, timesteps, vert. levels, nodes):  (1, 50, 3, 11450)\n",
      "slope_y shape (variables, timesteps, vert. levels, nodes):  (1, 50, 3, 11450)\n",
      "flux_u shape (variables, timesteps, vert. levels, nodes):  (1, 50, 3, 11450)\n",
      "flux_v shape (variables, timesteps, vert. levels, nodes):  (1, 50, 3, 11450)\n"
     ]
    }
   ],
   "source": [
    "## Load dummy data and convert to DataArray:\n",
    "\n",
    "# Slopes S_x and S_y, used as input data:\n",
    "slope_x = xr.open_dataset(Path(path_to_data + '/input_slope_x.nc')).to_array()\n",
    "slope_y = xr.open_dataset(Path(path_to_data + '/input_slope_y.nc')).to_array()\n",
    "\n",
    "# Temperatur flux u*T in x- and y- direction, referred to as flux_u and and flux_y, respectively, used as targets:\n",
    "flux_u = xr.open_dataset(Path(path_to_data + '/output_uflux.nc')).to_array()\n",
    "flux_v = xr.open_dataset(Path(path_to_data + '/output_vflux.nc')).to_array()\n",
    "\n",
    "# Check dimensions:\n",
    "print('slope_x shape (variables, timesteps, vert. levels, nodes): ',slope_x.shape)\n",
    "print('slope_y shape (variables, timesteps, vert. levels, nodes): ',slope_y.shape)\n",
    "print('flux_u shape (variables, timesteps, vert. levels, nodes): ',flux_u.shape)\n",
    "print('flux_v shape (variables, timesteps, vert. levels, nodes): ',flux_v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad5aa33",
   "metadata": {},
   "source": [
    "### Preprocess data\n",
    "\n",
    "This block serves as a placeholder. Until we have the final data, we skip parts of the preprocessing. In particular, we do not care about normalization and/or scaling of input and target data.\n",
    "\n",
    "In the first step, we only have isopycnal slopes in x- and y-direction ($S_x$ and $S_y$) as input data to predict temperature fluxes $u'T'$ and $v'T'$. Thus, we have two input and two output channels (or \"features\").\n",
    "\n",
    "As baseline, we set up a number of multilayer perceptron (MLP) models, one model for each vertical level.\n",
    "And to keep it as simple as possible, we have a one-to-one relation for each grid point at a certain timestep. In other words, to predict temperature fluxes for a certain grid point and timestep, we restrict ourselves to only use input information for that specific grid point at that specific timestep. (As an extension, we may allow spatially neighboring grid points' information to be involved as additional input information and/or consider current ($t=0$) plus a certain number $N$ of past timesteps ($t<0$) to improve our prediction.)\n",
    "\n",
    "In this baseline szenario with a one-to-one relation, each grid point can be treated as an individual sample and we can flatten the time dimension. This gives us $50 \\cdot 11450$ (= number of timesteps times number of grid points) input samples for each of the $3$ vertical levels. \n",
    "\n",
    "Usually, the input data is split into training, validation and test data. Training data serves for training the model. Validation data is needed for tuning any hyperparameters. Ultimately, test data is only used for model evaluation. For simplicity, we use 30 / 10 / 10 timesteps for training / validation / test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "17bd4df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data\n",
      "==========\n",
      "train_input shape (number of samples, number of input features): (343500, 2)\n",
      "val_input shape (number of samples, number of input features): (114500, 2)\n",
      "test_input shape (number of samples, number of input features): (114500, 2)\n",
      "\n",
      "Target data\n",
      "===========\n",
      "train_target shape (number of samples, number of input features): (343500, 2)\n",
      "val_target shape (number of samples, number of input features): (114500, 2)\n",
      "test_target shape (number of samples, number of input features): (114500, 2)\n"
     ]
    }
   ],
   "source": [
    "## Prepare training, validation and test data for inputs and targets:\n",
    "\n",
    "# As an example, extract data for the first vertical level (v1):\n",
    "slope_x_v1 = slope_x[:,:,0,:]\n",
    "slope_y_v1 = slope_y[:,:,0,:]\n",
    "flux_u_v1 = flux_u[:,:,0,:]\n",
    "flux_v_v1 = flux_v[:,:,0,:]\n",
    "\n",
    "# Concatenate inputs and targets, to have two channels, each:\n",
    "input_v1_concat = np.concatenate([slope_x_v1,slope_y_v1], axis=0)\n",
    "target_v1_concat = np.concatenate([flux_u_v1,flux_v_v1], axis=0)\n",
    "\n",
    "# Split inputs and targets into training, validation and test sets:\n",
    "train_input_v1_concat = input_v1_concat[:,:30,:]\n",
    "val_input_v1_concat = input_v1_concat[:,30:40,:]\n",
    "test_input_v1_concat = input_v1_concat[:,40:,:]\n",
    "train_target_v1_concat = target_v1_concat[:,:30,:]\n",
    "val_target_v1_concat = target_v1_concat[:,30:40,:]\n",
    "test_target_v1_concat = target_v1_concat[:,40:,:]\n",
    "\n",
    "# Flatten number of timesteps and number of gridpoints by reshaping. \n",
    "# Only keep the number of channels as first dimension:\n",
    "train_input_v1_concat_flat = np.reshape(train_input_v1_concat,([train_input_v1_concat.shape[0],-1]))\n",
    "val_input_v1_concat_flat = np.reshape(val_input_v1_concat,([val_input_v1_concat.shape[0],-1]))\n",
    "test_input_v1_concat_flat = np.reshape(test_input_v1_concat,([test_input_v1_concat.shape[0],-1]))\n",
    "train_target_v1_concat_flat = np.reshape(train_target_v1_concat,([train_target_v1_concat.shape[0],-1]))\n",
    "val_target_v1_concat_flat = np.reshape(val_target_v1_concat,([val_target_v1_concat.shape[0],-1]))\n",
    "test_target_v1_concat_flat = np.reshape(test_target_v1_concat,([test_target_v1_concat.shape[0],-1]))\n",
    "\n",
    "# Ultimately, swap dimensions, to have [number of samples, number of features]:\n",
    "train_input = np.swapaxes(train_input_v1_concat_flat,0,1)\n",
    "val_input = np.swapaxes(val_input_v1_concat_flat,0,1)\n",
    "test_input = np.swapaxes(test_input_v1_concat_flat,0,1)\n",
    "train_target = np.swapaxes(train_target_v1_concat_flat,0,1)\n",
    "val_target = np.swapaxes(val_target_v1_concat_flat,0,1)\n",
    "test_target = np.swapaxes(test_target_v1_concat_flat,0,1)\n",
    "\n",
    "## Check dimensions:\n",
    "\n",
    "# Input data:\n",
    "print('Input data')\n",
    "print('==========')\n",
    "print('train_input shape (number of samples, number of input features):', train_input.shape)\n",
    "print('val_input shape (number of samples, number of input features):', val_input.shape)\n",
    "print('test_input shape (number of samples, number of input features):', test_input.shape)\n",
    "print('\\nTarget data')\n",
    "print('===========')\n",
    "print('train_target shape (number of samples, number of input features):', train_target.shape)\n",
    "print('val_target shape (number of samples, number of input features):', val_target.shape)\n",
    "print('test_target shape (number of samples, number of input features):', test_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c235cd",
   "metadata": {},
   "source": [
    "### Model setup: Multilayer perceptron\n",
    "\n",
    "Now we got the input an target data in the correct shape for setting up our first multilayer perceptron (MLP). Keep in mind, here, we focus on data for the first vertical level (v1), as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dff5bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries:\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    LSTM,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    BatchNormalization,\n",
    "    LeakyReLU,\n",
    "    concatenate,\n",
    ")\n",
    "from tensorflow.keras.optimizers import (\n",
    "    SGD,\n",
    "    Adam,\n",
    ")\n",
    "import tensorflow.keras.initializers as tfi\n",
    "import tensorflow.keras.regularizers as tfr\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as Kl\n",
    "\n",
    "# Suppress Tensorflow warnings\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1f44e3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MLP\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                60        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 281\n",
      "Trainable params: 281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-29 12:03:03.207622: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "## Prepare MLP:\n",
    "\n",
    "# Set some parameters upfront:\n",
    "lr = 0.0005 # Learning rate\n",
    "epc = 10 # Number of epochs\n",
    "batch_size = 10 # Batch size\n",
    "in_features = train_input.shape[1] # Number of input features\n",
    "out_features = train_target.shape[1] # Number of output features\n",
    "\n",
    "# Optionally use L1 and/or L2 regularization to drive small weights to zero or penalize large weights:\n",
    "kernel_reg_Dense=tfr.l1_l2(l1=0, l2=0)\n",
    "\n",
    "## Set up MLP - layer by layer: (Another way is to set up a \"sequential model\", which I can show you later!)\n",
    "\n",
    "# Input layer, the input shape is determined by the number of input features:\n",
    "inputs = Input(shape=(in_features))\n",
    "\n",
    "# First hidden layer with 20 neurons and a linear activation function is connected to the input layer:\n",
    "hidden_1 = Dense(20, activation='linear', kernel_regularizer=kernel_reg_Dense)(inputs)\n",
    "\n",
    "# Second hidden layer with 10 neurons and a linear activation function is connected to the first hidden layer:\n",
    "hidden_2 = Dense(10, activation='linear', kernel_regularizer=kernel_reg_Dense)(hidden_1)\n",
    "\n",
    "# Finally, we have an output layer, connected to the second hidden layer, \n",
    "# to predict the desired number of output features:\n",
    "output = Dense(1, activation='linear')(hidden_2)\n",
    "\n",
    "## Define and compile model:\n",
    "\n",
    "# Formally set up the model, starting with the defined input layer, ending with the defined output layer:\n",
    "model_MLP = Model(inputs, output, name='MLP')\n",
    "\n",
    "# For training the weights and biases, we use a so-called optimizer. Here we use the Adam optimizer, \n",
    "# which is an often used optimizer, related to stochastic gradient descent learning.\n",
    "# The optimizer needs the learning rate as parameter, determining how fast the weights and biases are adjusted\n",
    "# in the learning process. The learning rate is one of the hyper-parameters, that need to be tuned later.\n",
    "opt = Adam(lr=lr) #SGD(lr=lr)\n",
    "\n",
    "# Compiling the model means, choosing a loss function (here: mean squared error mse), \n",
    "# connecting the optimizer to the model and choosing a number of evaluation metrics. \n",
    "# Here, we don't have any additional metrics, yet. We are only interested in the mse loss.\n",
    "model_MLP.compile(loss='mse', optimizer=opt, metrics=[])\n",
    "\n",
    "# Get a model summary, including the number of trainable parameters:\n",
    "model_MLP.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3121f3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34350/34350 [==============================] - 12s 358us/step - loss: 0.0350 - val_loss: 0.0199\n",
      "Epoch 2/10\n",
      "34350/34350 [==============================] - 12s 361us/step - loss: 0.0350 - val_loss: 0.0200 - loss: 0.035 - ETA: 6s - loss: 0.03  - E  - ET - ETA: 0s - los\n",
      "Epoch 3/10\n",
      "34350/34350 [==============================] - 12s 362us/step - loss: 0.0350 - val_loss: 0.0199\n",
      "Epoch 4/10\n",
      "34350/34350 [==============================] - 12s 362us/step - loss: 0.0350 - val_loss: 0.0200ETA: 2s -  - ETA: - ETA: - ETA: 0s - loss: 0.\n",
      "Epoch 5/10\n",
      "34350/34350 [==============================] - 12s 363us/step - loss: 0.0350 - val_loss: 0.0199 loss: 0.0 - ETA: 5s - loss: 0 - ETA: 4s - lo - ETA: 4s - loss: 0.0 - ETA: 4s - lo\n",
      "Epoch 6/10\n",
      "34350/34350 [==============================] - 13s 366us/step - loss: 0.0350 - val_loss: 0.0199\n",
      "Epoch 7/10\n",
      "34350/34350 [==============================] - 13s 386us/step - loss: 0.0350 - val_loss: 0.0200\n",
      "Epoch 8/10\n",
      "34350/34350 [==============================] - 15s 436us/step - loss: 0.0350 - val_loss: 0.0199\n",
      "Epoch 9/10\n",
      "34350/34350 [==============================] - 13s 388us/step - loss: 0.0350 - val_loss: 0.0200\n",
      "Epoch 10/10\n",
      "34350/34350 [==============================] - 13s 389us/step - loss: 0.0350 - val_loss: 0.0199\n"
     ]
    }
   ],
   "source": [
    "# Train model on data for vertical level v1. Therefore, we specify which data shall be used for training and\n",
    "# validation. We set the number of training epochs and the batch size.\n",
    "# And the data is shuffled after each training epoch (shuffle=True).\n",
    "history = model_MLP.fit(train_input, train_target, epochs=epc, verbose=1, shuffle=True,\n",
    "                        batch_size=batch_size, validation_data=(val_input, val_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7f9eee4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss (mse) on train and validation data:\n",
    "fig, axes = plt.subplots(1, 1, figsize=(13,8))\n",
    "axes.set_title(\"Evaluate training process: Loss (mse) on training and validation data\", fontsize=16)\n",
    "axes.plot(history.history['loss'], label='train loss'), \n",
    "axes.plot(history.history['val_loss'], label='validation loss')\n",
    "axes.set_ylabel(\"loss (mse)\", fontsize=16)\n",
    "axes.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd7915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model predictions on training, validation and test data from trained model:\n",
    "train_pred = model_MLP.predict(train_input)\n",
    "val_pred = model_MLP.predict(val_input)\n",
    "test_pred = model_MLP.predict(test_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716aa407",
   "metadata": {},
   "source": [
    "### Discussion on baseline MLP model on dummy data\n",
    "\n",
    "This tutorial shows first steps for setting up a basic multilayer perceptron.\n",
    "The loss curves appear to be just flat. This tells us, that there is no real training progress.\n",
    "\n",
    "--> We need to wait for the final data :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c616ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
